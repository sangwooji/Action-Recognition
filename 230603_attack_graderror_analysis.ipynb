{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9aa78f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import numpy as np\n",
    "import itertools\n",
    "import models\n",
    "from models import ConvLSTM\n",
    "from dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import argparse\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b19240ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flickerfusion.utils import *\n",
    "from flickerfusion.attacks import LinfAttack, L2Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "390b83cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'model_checkpoints/model_nodecay_30.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b61a81c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb7a38b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jun  4 12:48:55 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN Xp            Off  | 00000000:05:00.0 Off |                  N/A |\n",
      "| 20%   41C    P0    61W / 250W |      0MiB / 12194MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  TITAN Xp            Off  | 00000000:09:00.0 Off |                  N/A |\n",
      "| 33%   50C    P0    60W / 250W |      0MiB / 12196MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  TITAN RTX           Off  | 00000000:0B:00.0 Off |                  N/A |\n",
      "| 23%   37C    P0    31W / 280W |      0MiB / 24220MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b714e772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvLSTM(\n",
       "  (encoder): Encoder(\n",
       "    (feature_extractor): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (6): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (7): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (6): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (7): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (8): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (9): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (10): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (11): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (12): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (13): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (14): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (15): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (16): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (17): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (18): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (19): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (20): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (21): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (22): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (23): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (24): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (25): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (26): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (27): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (28): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (29): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (30): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (31): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (32): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (33): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (34): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (35): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (7): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    )\n",
       "    (final): Sequential(\n",
       "      (0): Linear(in_features=2048, out_features=512, bias=True)\n",
       "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (lstm): LSTM(\n",
       "    (lstm): LSTM(512, 1024, batch_first=True, bidirectional=True)\n",
       "  )\n",
       "  (output_layers): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=1024, out_features=101, bias=True)\n",
       "    (4): Softmax(dim=-1)\n",
       "  )\n",
       "  (attention_layer): Linear(in_features=2048, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define network\n",
    "model = ConvLSTM(\n",
    "    num_classes=101,\n",
    "    latent_dim=512,\n",
    "    lstm_layers=1,\n",
    "    hidden_dim=1024,\n",
    "    bidirectional=True,\n",
    "    #attention=True,\n",
    ")\n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6009cad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sangwooji/miniconda3/envs/colorfusion/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n"
     ]
    }
   ],
   "source": [
    "# Get videos with all frames, as a result, batch_size should be 1\n",
    "test_dataset = Dataset(\n",
    "    dataset_path=\"data/UCF-101-frames/\",\n",
    "    split_path=\"data/ucfTrainTestlist\",\n",
    "    split_number=1,\n",
    "    input_shape=(3,224,224),\n",
    "    sequence_length=40,\n",
    "    training=False,\n",
    ")\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "079dc925",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = total = 0\n",
    "for batch_i, (images, labels) in enumerate(test_dataloader):\n",
    "    break\n",
    "images = images.to(device)\n",
    "labels = labels.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8237c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a6811db2",
   "metadata": {},
   "source": [
    "Attempt #1: very basic adversarial examples with ConvLSTM"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1bf5a9b6",
   "metadata": {},
   "source": [
    "# images can be classified with net\n",
    "print (images.shpae)\n",
    "result.max(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e944176b",
   "metadata": {},
   "outputs": [],
   "source": [
    "perturbation = torch.ones(3,224,224).to(device)\n",
    "perturbation.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fce24d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net.lstm.train()\n",
    "torch.backends.cudnn.enabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "492e5540",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "adv = images+perturbation\n",
    "adv_result = net(adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b866cafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "loss = loss_fn(adv_result, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc11b2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9cf8fe42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-4.8964e-05,  1.3020e-05,  5.3427e-05,  ..., -2.7034e-06,\n",
       "           3.1119e-05,  3.4413e-05],\n",
       "         [-7.7601e-05,  8.9612e-05,  1.2403e-04,  ...,  1.0433e-05,\n",
       "           3.0507e-05,  2.9955e-05],\n",
       "         [-5.4946e-05,  2.3295e-05,  1.3957e-04,  ..., -1.1914e-05,\n",
       "          -3.7560e-06,  3.0114e-05],\n",
       "         ...,\n",
       "         [-2.7529e-05, -2.8413e-05,  1.7740e-05,  ...,  5.0725e-05,\n",
       "           2.5488e-05,  8.6416e-06],\n",
       "         [-1.6701e-05, -1.5975e-06, -9.9887e-08,  ..., -1.6522e-05,\n",
       "           2.2767e-05, -1.3772e-06],\n",
       "         [ 1.7332e-05,  7.3597e-06, -4.6168e-06,  ...,  2.3592e-05,\n",
       "          -4.2898e-06, -1.1193e-04]],\n",
       "\n",
       "        [[-3.2781e-05, -1.6968e-06,  2.1020e-05,  ..., -3.6889e-05,\n",
       "          -8.0709e-07,  1.5357e-05],\n",
       "         [-6.4874e-05,  6.6567e-05,  6.5496e-05,  ..., -3.6593e-05,\n",
       "          -1.0825e-05, -1.4934e-05],\n",
       "         [-5.5583e-05, -7.7941e-06,  1.0270e-04,  ..., -3.7225e-05,\n",
       "          -3.9511e-05, -2.4441e-05],\n",
       "         ...,\n",
       "         [-4.0342e-05, -2.9555e-05,  1.7713e-05,  ..., -1.9114e-05,\n",
       "           8.3034e-06,  3.9671e-06],\n",
       "         [-2.0919e-05, -7.6129e-06, -1.9050e-05,  ..., -2.5898e-05,\n",
       "           3.8893e-05,  1.0318e-05],\n",
       "         [ 8.2844e-06, -8.0008e-06, -3.0234e-05,  ...,  2.4995e-05,\n",
       "           1.1224e-05, -1.1658e-04]],\n",
       "\n",
       "        [[ 3.3207e-05,  2.8008e-06,  4.4752e-06,  ...,  2.9669e-05,\n",
       "           7.1483e-07,  2.9894e-05],\n",
       "         [ 1.5123e-05,  3.7656e-05,  5.8308e-06,  ...,  2.3954e-05,\n",
       "           1.5263e-06,  2.2250e-06],\n",
       "         [ 1.5521e-05, -8.4392e-06,  3.8368e-05,  ...,  2.4117e-05,\n",
       "          -3.0954e-06, -2.6097e-06],\n",
       "         ...,\n",
       "         [-1.2792e-05, -1.9434e-06,  1.0748e-05,  ..., -3.2036e-05,\n",
       "          -8.6212e-06, -1.4714e-06],\n",
       "         [-1.1437e-06,  1.1626e-05, -4.6906e-06,  ..., -2.7861e-05,\n",
       "           2.5257e-05,  2.3350e-05],\n",
       "         [ 5.4702e-06, -2.6048e-06, -1.1918e-05,  ...,  8.3339e-06,\n",
       "           2.5254e-05, -3.3200e-05]]], device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perturbation.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efb8a898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jun  4 12:49:06 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  TITAN Xp            Off  | 00000000:05:00.0 Off |                  N/A |\r\n",
      "| 21%   41C    P0    61W / 250W |      0MiB / 12194MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  TITAN Xp            Off  | 00000000:09:00.0 Off |                  N/A |\r\n",
      "| 29%   54C    P2    79W / 250W |   9239MiB / 12196MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   2  TITAN RTX           Off  | 00000000:0B:00.0 Off |                  N/A |\r\n",
      "| 33%   37C    P0    28W / 280W |      0MiB / 24220MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    1       698      C   .../miniconda3/envs/colorfusion/bin/python  9229MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bf681a57",
   "metadata": {},
   "source": [
    "#4 Step-by-step grad analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19a2e49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "perturbation = torch.ones(3,224,224).to(device)\n",
    "perturbation.requires_grad = True\n",
    "adv = images+perturbation\n",
    "torch.backends.cudnn.enabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4f54f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Encoder(\n",
    "    latent_dim=512,\n",
    ")\n",
    "model.eval()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2dabe4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model(adv[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "867c18f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([164, 512])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cbe046d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "toLogit = torch.nn.Linear(164*512, 101).to(device)\n",
    "logit = toLogit(results.reshape(1,-1))\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "loss = loss_fn(logit, labels)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "77b67c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(perturbation.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1f68c05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c9e5743",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dce550",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "26c6933a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (lstm): LSTM(512, 1024, batch_first=True, bidirectional=True)\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm = models.LSTM(512, 1, 1024, True)\n",
    "lstm.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4de6d081",
   "metadata": {},
   "outputs": [],
   "source": [
    "results2 = lstm(results.view(1, results.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e5e97a05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 164, 2048])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6fde16ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=2048, out_features=1, bias=True)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = torch.nn.Linear(2048, 1)\n",
    "linear.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1840cf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "results3 = linear(results2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a06295e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d80f58de",
   "metadata": {},
   "outputs": [],
   "source": [
    "results4 = F.softmax(results3.squeeze(-1), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "aff1091d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results5 = torch.sum(results4.unsqueeze(-1) * results2, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "916284a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SumBackward1 at 0x7fbb1ffe48d0>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results5.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "61427d59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "  (1): BatchNorm1d(1024, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  (2): ReLU()\n",
       "  (3): Linear(in_features=1024, out_features=101, bias=True)\n",
       "  (4): Softmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_dim = 1024 \n",
    "num_classes = 101\n",
    "output_layers = torch.nn.Sequential(\n",
    "    torch.nn.Linear(2 * hidden_dim, hidden_dim),\n",
    "    torch.nn.BatchNorm1d(hidden_dim, momentum=0.01),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(hidden_dim, num_classes),\n",
    "    torch.nn.Softmax(dim=-1),\n",
    ")\n",
    "output_layers.eval()\n",
    "output_layers.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c64ebbc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2048])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "23615fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results6 = output_layers(results5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c7be991d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0101, 0.0096, 0.0101, 0.0096, 0.0101, 0.0100, 0.0098, 0.0102, 0.0097,\n",
       "         0.0099, 0.0099, 0.0101, 0.0099, 0.0098, 0.0098, 0.0102, 0.0103, 0.0097,\n",
       "         0.0101, 0.0101, 0.0102, 0.0102, 0.0100, 0.0097, 0.0101, 0.0098, 0.0102,\n",
       "         0.0101, 0.0098, 0.0099, 0.0100, 0.0100, 0.0099, 0.0102, 0.0100, 0.0096,\n",
       "         0.0099, 0.0097, 0.0098, 0.0098, 0.0097, 0.0102, 0.0098, 0.0099, 0.0098,\n",
       "         0.0098, 0.0097, 0.0098, 0.0101, 0.0098, 0.0098, 0.0103, 0.0102, 0.0102,\n",
       "         0.0099, 0.0099, 0.0096, 0.0098, 0.0100, 0.0099, 0.0097, 0.0096, 0.0097,\n",
       "         0.0098, 0.0100, 0.0098, 0.0097, 0.0102, 0.0101, 0.0097, 0.0096, 0.0100,\n",
       "         0.0101, 0.0098, 0.0097, 0.0100, 0.0097, 0.0099, 0.0098, 0.0097, 0.0098,\n",
       "         0.0098, 0.0099, 0.0099, 0.0098, 0.0098, 0.0099, 0.0098, 0.0100, 0.0098,\n",
       "         0.0098, 0.0100, 0.0098, 0.0101, 0.0099, 0.0102, 0.0097, 0.0099, 0.0099,\n",
       "         0.0100, 0.0097]], device='cuda:0', grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e477d5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "loss = loss_fn(results6, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5969e557",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time, but the saved intermediate results have already been freed. Specify retain_graph=True when calling .backward() or autograd.grad() the first time.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31997/2859123600.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/colorfusion/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/colorfusion/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time, but the saved intermediate results have already been freed. Specify retain_graph=True when calling .backward() or autograd.grad() the first time."
     ]
    }
   ],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0292b842",
   "metadata": {},
   "outputs": [],
   "source": [
    "perturbation.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b821fb39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1460179",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "efabbe5e",
   "metadata": {},
   "source": [
    "#2 LSTM perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54e59940",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.nn.LSTM(512, 1024, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fd8aa47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(512, 1024, num_layers=2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b786929a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = torch.rand(1,1,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f06f5117",
   "metadata": {},
   "outputs": [],
   "source": [
    "perturbation = torch.ones_like(sample)\n",
    "perturbation.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1bf2a39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv = sample + perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f2a9e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = net(adv)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82dc9d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = torch.nn.Linear(1024, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "472e0634",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = linear(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2de47d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc641a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = torch.ones(1).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e219dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_fn(r[0], label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a9b93323",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dd2c9c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 512])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perturbation.grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3031a46f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.9206e-04, -4.5834e-04, -7.0031e-05,  2.0036e-04,  3.6439e-04,\n",
       "           5.9452e-06,  6.6198e-04,  5.8982e-04,  3.6445e-04,  1.2748e-04,\n",
       "           1.4688e-04, -1.4086e-04,  4.8118e-04,  5.5115e-05,  5.0407e-04,\n",
       "           5.0873e-04, -1.1349e-04, -1.1487e-04,  7.0009e-05, -2.5364e-04,\n",
       "           7.5248e-05,  1.5622e-04, -8.0532e-04, -2.1022e-04, -1.6068e-05,\n",
       "          -2.3742e-04, -5.0388e-05, -3.3451e-04,  1.1708e-05, -5.0915e-04,\n",
       "           4.9320e-05, -6.1708e-04,  8.3335e-05,  2.9895e-04, -4.1996e-04,\n",
       "          -4.3888e-04,  3.3830e-04, -1.2647e-04,  5.7912e-04, -1.5746e-04,\n",
       "           2.3566e-04,  1.1325e-04, -2.6284e-04,  4.6794e-04,  1.5082e-04,\n",
       "           1.4786e-04,  1.4837e-04,  2.1347e-05,  6.4414e-04, -3.8998e-05,\n",
       "          -3.1261e-05,  4.9590e-04, -1.8191e-04,  1.8967e-04,  1.8622e-04,\n",
       "          -3.1657e-05,  1.9699e-04,  3.6595e-04,  1.5152e-04,  2.6320e-04,\n",
       "          -2.0029e-05, -9.6789e-05, -8.2520e-05, -6.9029e-04,  1.2553e-04,\n",
       "          -2.9264e-04,  6.5949e-05,  2.4697e-04, -1.3371e-04, -2.5349e-04,\n",
       "          -1.1699e-04, -1.9586e-04,  3.3709e-04,  1.8275e-04,  1.3332e-04,\n",
       "           3.1423e-04, -1.1418e-04,  7.3804e-04, -9.4079e-05,  2.0817e-04,\n",
       "          -3.3910e-04,  3.7903e-04, -3.5072e-04,  1.4100e-04, -1.3233e-04,\n",
       "          -1.6500e-05, -2.0860e-04,  5.7306e-05, -1.5500e-04,  5.4382e-04,\n",
       "           1.6391e-04,  6.0196e-05,  1.2933e-04,  2.0663e-04, -2.1262e-06,\n",
       "           2.0595e-04,  2.9318e-04, -3.1147e-04,  8.7780e-04,  1.2177e-04,\n",
       "           1.4829e-04, -2.3073e-04,  4.2821e-04,  4.1784e-06, -3.2751e-05,\n",
       "           4.4620e-04,  5.3965e-05, -4.6298e-04, -2.4795e-04, -1.6337e-04,\n",
       "          -9.8809e-05,  3.6932e-04,  1.7404e-04, -7.4843e-05, -4.1883e-04,\n",
       "          -4.0266e-05, -5.1309e-05,  5.7729e-05, -1.2503e-04, -2.0988e-04,\n",
       "           6.1113e-04,  3.0160e-04,  4.6006e-04, -6.2784e-04,  5.0429e-04,\n",
       "           2.5009e-04, -4.3626e-04, -6.7541e-05,  5.3057e-04, -6.6691e-04,\n",
       "          -4.0244e-04,  4.5309e-04, -2.5223e-04,  8.0554e-04,  1.1742e-05,\n",
       "          -5.3025e-04,  8.2885e-06, -3.0028e-04,  3.0704e-04, -5.8676e-05,\n",
       "           5.6502e-04, -3.7573e-05,  9.6078e-05,  1.5939e-05,  2.2694e-04,\n",
       "           9.9114e-05,  3.4896e-04,  9.7225e-05,  2.1745e-04, -5.5058e-04,\n",
       "           1.5515e-04, -2.6587e-04, -6.2752e-05,  1.7014e-04, -4.6647e-05,\n",
       "          -1.5067e-04,  3.4697e-05, -9.0946e-05, -2.1269e-04,  1.4132e-04,\n",
       "          -2.1485e-04,  1.7810e-04, -1.3550e-05, -7.5327e-05, -4.5487e-04,\n",
       "          -4.4813e-04,  9.0635e-05,  1.8637e-04, -5.1601e-04,  1.0329e-04,\n",
       "           1.2084e-04,  3.2180e-04, -2.4102e-06,  5.9341e-06, -1.6673e-04,\n",
       "           2.0803e-04,  4.6830e-04, -9.2873e-05,  1.0796e-04, -1.0755e-04,\n",
       "          -2.1804e-04, -5.1437e-04, -2.8315e-04, -1.9728e-04, -3.0016e-04,\n",
       "          -1.1375e-04, -3.1771e-04,  3.6201e-04,  3.5868e-04,  3.7359e-04,\n",
       "          -5.0293e-05,  1.9432e-04,  6.5318e-04,  1.3451e-04,  6.8103e-04,\n",
       "           3.3998e-04, -2.4592e-04, -2.3588e-04, -3.5174e-04,  3.4495e-05,\n",
       "          -4.4685e-04, -5.2403e-04, -2.5334e-04, -1.2849e-04, -8.9823e-05,\n",
       "          -8.8797e-05,  1.1143e-04,  5.1917e-04, -2.9654e-04, -1.3975e-04,\n",
       "          -1.0295e-04,  6.9091e-05,  3.5537e-05, -4.7308e-05,  2.0262e-04,\n",
       "          -2.2048e-04,  1.0319e-04, -2.0085e-04, -3.5434e-04, -2.0898e-04,\n",
       "          -2.1065e-04,  1.4140e-04, -5.4856e-04, -4.5407e-04, -4.0869e-04,\n",
       "          -5.4798e-04, -3.4319e-04, -9.3191e-04, -1.0504e-04,  1.8675e-04,\n",
       "          -5.2531e-05,  8.5326e-05,  1.7485e-05, -2.1217e-04,  4.6317e-04,\n",
       "           6.9397e-04,  4.9898e-04,  9.2660e-06, -6.0863e-04, -6.0070e-05,\n",
       "           6.7017e-04,  7.6727e-05,  3.7618e-04,  1.2709e-04, -1.9004e-04,\n",
       "           2.1360e-04,  2.2958e-06,  3.7387e-04,  5.9921e-04, -3.8515e-04,\n",
       "           1.0072e-04,  5.5639e-04, -3.2282e-04, -2.4927e-04,  1.0127e-04,\n",
       "          -5.0100e-05,  2.7704e-04, -2.4065e-04, -3.5849e-04,  2.8889e-04,\n",
       "          -7.2184e-04, -3.9481e-05,  3.2727e-04,  2.8285e-04,  1.9723e-04,\n",
       "           1.4388e-04,  2.5700e-05, -2.0658e-04, -1.9627e-04,  2.0608e-04,\n",
       "          -1.2220e-03, -5.9623e-04, -2.3411e-04, -3.2928e-04,  1.3909e-04,\n",
       "           2.6148e-04, -1.4918e-04, -1.6245e-04,  4.4208e-05, -2.8770e-04,\n",
       "           1.6835e-04, -3.1745e-04, -4.8789e-04, -6.6837e-05, -5.0498e-04,\n",
       "           1.5458e-04,  1.1845e-04, -2.1953e-04, -3.6689e-05,  3.7769e-04,\n",
       "           1.2821e-05, -4.7070e-04,  6.0429e-05,  7.3247e-04, -5.3812e-07,\n",
       "           3.4757e-04, -4.5393e-04, -6.9113e-05, -1.4658e-04,  6.2637e-05,\n",
       "           9.6219e-05,  9.9762e-05, -2.6813e-04,  7.8754e-05, -1.7756e-04,\n",
       "          -9.2192e-04, -2.0884e-04,  1.4098e-04, -6.8080e-05, -4.9364e-05,\n",
       "          -1.2735e-05,  1.2982e-04, -6.0594e-05, -5.3862e-04,  1.9334e-04,\n",
       "           4.0208e-04, -1.5055e-04, -2.2356e-04,  3.5717e-04, -1.6280e-04,\n",
       "           6.2865e-04,  4.6299e-04,  2.7212e-04, -1.1831e-04, -3.1050e-04,\n",
       "          -1.4256e-04,  6.5024e-04, -3.4765e-04,  5.1914e-04, -3.2135e-04,\n",
       "           1.4291e-04, -2.2569e-04,  3.7473e-04,  1.3998e-04, -3.3195e-05,\n",
       "          -4.0192e-04, -5.1370e-04, -3.9093e-04,  2.0187e-04, -5.5301e-05,\n",
       "          -1.6279e-04,  3.1749e-04,  3.5471e-04,  1.5460e-04,  4.1693e-04,\n",
       "          -3.6332e-04, -2.0120e-04,  8.9753e-05, -1.6054e-04,  2.9548e-04,\n",
       "           5.0015e-04, -2.6440e-04,  5.6101e-04,  8.3341e-05,  2.1172e-04,\n",
       "          -3.0005e-04, -9.3777e-05, -5.0697e-04, -4.3109e-05, -3.8308e-04,\n",
       "          -3.0908e-04,  2.1071e-04,  3.2097e-04, -1.3999e-05, -1.8427e-05,\n",
       "           2.7103e-04,  3.3563e-04, -4.5333e-04, -2.1522e-04,  5.3769e-04,\n",
       "          -1.8777e-05, -3.1355e-04, -1.1479e-04, -3.6256e-05,  6.6477e-04,\n",
       "          -2.4359e-04, -4.7055e-05,  8.2054e-05, -2.0201e-04,  3.9742e-05,\n",
       "           6.9383e-04,  5.7011e-04,  4.3313e-05,  1.4156e-04, -7.3857e-05,\n",
       "          -1.2623e-04,  1.0219e-04,  1.5707e-04,  5.7635e-04, -5.2327e-05,\n",
       "          -4.5454e-05, -2.1503e-04,  1.9265e-04, -3.2521e-04, -1.7641e-04,\n",
       "           4.0353e-05, -1.8732e-04, -1.2040e-04,  6.5639e-04,  1.8577e-06,\n",
       "           6.6372e-06,  2.7487e-04,  2.6981e-05, -3.3235e-04,  3.0726e-04,\n",
       "          -1.8910e-04,  3.0543e-04, -5.4276e-04,  6.3087e-06,  1.3449e-04,\n",
       "           1.0752e-04,  3.1209e-04, -1.1888e-04,  1.6909e-04, -4.7319e-05,\n",
       "          -4.4470e-04, -7.7010e-05,  2.3594e-04, -5.0248e-04,  2.5255e-04,\n",
       "           4.2746e-04,  2.2186e-04, -9.1961e-05,  3.2039e-04, -2.2846e-04,\n",
       "           3.4496e-05, -1.7453e-04, -1.5971e-04, -7.1084e-05,  1.1021e-04,\n",
       "           1.7832e-04,  2.4068e-04,  7.7443e-05,  1.0042e-04, -3.4929e-04,\n",
       "           2.3786e-04, -3.4581e-04, -1.6953e-04,  5.7131e-04, -2.5120e-04,\n",
       "           5.5023e-04, -7.6075e-04,  1.5457e-04, -4.2186e-04,  1.6351e-04,\n",
       "           8.1419e-05, -1.6383e-04,  3.2307e-04,  2.1101e-04, -2.6734e-04,\n",
       "          -2.5951e-04, -1.2922e-05,  8.1864e-05, -1.5988e-04,  9.2411e-05,\n",
       "          -1.4086e-04, -5.5215e-04,  3.4927e-05,  2.4857e-05, -3.5055e-04,\n",
       "           4.7239e-04, -3.6280e-04, -3.1351e-04,  2.8569e-04,  1.3543e-04,\n",
       "          -2.8302e-04,  4.9091e-04, -9.6176e-05,  1.2547e-04,  1.0926e-04,\n",
       "          -7.1669e-04,  1.2787e-04,  1.4042e-04,  1.4240e-04, -6.9068e-04,\n",
       "          -1.6612e-04, -1.5404e-04, -5.9682e-04,  3.0328e-04, -1.7800e-04,\n",
       "          -6.5041e-05,  3.8528e-04, -1.0301e-04,  4.4394e-04,  2.4713e-04,\n",
       "          -5.4471e-05,  6.9396e-04, -3.8248e-04, -4.1333e-04,  6.0010e-05,\n",
       "          -3.3655e-04,  2.7867e-04,  4.3848e-04,  7.1055e-04,  2.6912e-04,\n",
       "          -8.9124e-06,  6.2770e-04, -2.5740e-04,  4.2505e-04, -4.3818e-04,\n",
       "           1.1958e-04, -2.4953e-04, -3.8425e-04, -3.2129e-06,  3.3950e-04,\n",
       "          -3.1987e-05, -8.6454e-05,  3.0736e-04, -3.4330e-04,  2.1852e-05,\n",
       "           6.3999e-06,  1.9611e-04]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perturbation.grad"
   ]
  },
  {
   "cell_type": "raw",
   "id": "250c64f6",
   "metadata": {},
   "source": [
    "ResNet can be used to compute gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a6b63bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.resnet import resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "35290b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = resnet50().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "284cd989",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = resnet(adv[0,0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1de6e3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_fn(result, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "928cbfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5a530d50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.1813e-03,  5.8156e-03, -1.7487e-03,  ...,  2.2420e-05,\n",
       "          -4.3434e-03,  1.6723e-03],\n",
       "         [-1.9304e-02,  4.5507e-03, -1.9298e-03,  ...,  6.3596e-04,\n",
       "           2.0108e-03, -9.2278e-03],\n",
       "         [-6.9206e-03,  1.1881e-02,  3.8085e-03,  ..., -9.1914e-03,\n",
       "           2.1022e-03,  4.6818e-04],\n",
       "         ...,\n",
       "         [ 1.4537e-02, -8.6498e-03, -3.7245e-03,  ..., -1.3832e-03,\n",
       "          -2.8592e-03, -7.7448e-04],\n",
       "         [ 4.9330e-03,  3.1738e-03,  4.4205e-03,  ..., -4.3441e-03,\n",
       "           1.9800e-03, -9.4934e-04],\n",
       "         [ 3.4057e-03,  3.8184e-03,  4.7175e-03,  ...,  3.6633e-03,\n",
       "          -9.1093e-04,  1.0815e-03]],\n",
       "\n",
       "        [[ 1.0627e-02,  3.3389e-03,  1.3233e-03,  ...,  2.2948e-03,\n",
       "           7.0601e-03,  1.8375e-05],\n",
       "         [-2.3413e-03,  7.8030e-03,  1.9006e-02,  ..., -3.1056e-03,\n",
       "           7.1637e-03, -4.7506e-03],\n",
       "         [-1.9420e-03, -1.1209e-02, -5.3635e-04,  ..., -9.8420e-04,\n",
       "           5.6251e-03,  8.0061e-03],\n",
       "         ...,\n",
       "         [ 5.0803e-04, -2.2452e-03,  3.5242e-04,  ...,  4.4095e-03,\n",
       "          -3.0714e-03,  2.7050e-03],\n",
       "         [ 3.6920e-03, -2.4707e-03, -4.9651e-03,  ...,  3.3919e-03,\n",
       "          -7.1531e-04,  5.8699e-04],\n",
       "         [-3.7919e-03,  8.3080e-03, -3.5281e-03,  ..., -2.5812e-03,\n",
       "           6.4712e-04, -1.7485e-03]],\n",
       "\n",
       "        [[-6.0443e-03, -3.6085e-03, -5.3729e-03,  ..., -1.1555e-02,\n",
       "          -2.8314e-03,  7.9838e-03],\n",
       "         [-1.4356e-02, -9.9942e-03, -1.2393e-02,  ..., -3.1683e-03,\n",
       "           1.6136e-04, -1.8618e-03],\n",
       "         [ 3.9506e-03, -1.1634e-02,  3.3335e-03,  ...,  9.1277e-03,\n",
       "           1.0603e-02, -4.7644e-03],\n",
       "         ...,\n",
       "         [ 8.4385e-03, -5.0692e-05, -1.2430e-02,  ...,  6.9054e-03,\n",
       "          -1.2841e-03, -3.8212e-04],\n",
       "         [-3.4768e-03,  4.0000e-03,  5.2179e-04,  ...,  4.2423e-03,\n",
       "           1.9809e-03, -1.5266e-03],\n",
       "         [-4.0395e-03,  2.4779e-03,  4.5483e-03,  ..., -1.4627e-05,\n",
       "           3.1981e-03,  2.5358e-04]]], device='cuda:0')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perturbation.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634fb417",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f741d3b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3a7713",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8015f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82dab582",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "config['row_mask_rate'] = 0\n",
    "config['row_mask_pad'] = 0\n",
    "config['rand_weight'] = 0\n",
    "config['rand_base'] = 0\n",
    "config['save_iter'] = 0\n",
    "config['coeff_xy'] = 0 \n",
    "config['nb_proj'] = 1\n",
    "aug = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d5faf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "# net.lstm.train()\n",
    "# net.attention_layer.train()\n",
    "batch_size = 1\n",
    "\n",
    "# adv_perturbation: lrgb [224, 224, 2]  \n",
    "input_size = 224\n",
    "adv_perturbation = torch.zeros((input_size,input_size,2)).to(device)\n",
    "adv_perturbation.requires_grad = True\n",
    "expand_to_lrgb = torch.Tensor([[1, 0],[-0.2126/0.7152, -0.0722/0.7152],[0,1]]).T.to(device)\n",
    "\n",
    "mask_range = input_size\n",
    "mask_size = int(mask_range * config['row_mask_rate'])\n",
    "t = torch.arange(0, mask_range, device=device).repeat(batch_size,1)\n",
    "pad = config['row_mask_pad']\n",
    "\n",
    "loss_sum = 0\n",
    "save_iter = config['save_iter']\n",
    "coeff_xy = config['coeff_xy']\n",
    "nb_proj = config['nb_proj']\n",
    "if coeff_xy >= 0:\n",
    "    mseloss = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "432138df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "video_lrgb = rgb2lrgb(images[0])\n",
    "net.zero_grad()\n",
    "\n",
    "#           # expand perturbation\n",
    "l_perturbation = torch.matmul(adv_perturbation, expand_to_lrgb).permute(2,0,1)\n",
    "\n",
    "adv_aug = lrgb2rgb(video_lrgb+l_perturbation)\n",
    "# # Random intensity\n",
    "# weight = torch.rand(1).to(device)\n",
    "# l_perturbation = (weight*config['rand_weight']+config['rand_base'])*l_perturbation\n",
    "\n",
    "# # Row masking\n",
    "# start_row = torch.randint(low=pad, high=mask_range-mask_size-pad, \\\n",
    "#                           size=(batch_size,1), device=device)\n",
    "# mask = t.ge(start_row) & t.lt(start_row+mask_size)\n",
    "# l_perturbation[mask.reshape(1,input_size,1).repeat(3,1,input_size)] = 0\n",
    "\n",
    "# # add perturbation\n",
    "# p_proj = project_perturbation(video_lrgb, l_perturbation, nb_proj)\n",
    "\n",
    "# temp = video_lrgb + p_proj\n",
    "# p_plus = torch.clamp(temp, 0, 1)\n",
    "# idx_plus = p_plus != temp\n",
    "# p_plus = p_plus - video_lrgb\n",
    "\n",
    "# temp = video_lrgb - p_proj\n",
    "# p_minus = torch.clamp(temp, 0, 1)\n",
    "# idx_minus = p_minus != temp\n",
    "# p_minus = video_lrgb - p_minus\n",
    "\n",
    "# p_clipped = torch.where(p_plus.abs() > p_minus.abs(), p_minus, p_plus)\n",
    "# p_clipped = torch.where(idx_plus | idx_minus, p_clipped, p_proj)\n",
    "# l_perturbation = p_clipped\n",
    "\n",
    "# # plus, minus, mixed\n",
    "# adv_minus = lrgb2rgb(torch.clamp(video_lrgb - l_perturbation, 0, 1))\n",
    "# adv_plus = lrgb2rgb(torch.clamp(video_lrgb + l_perturbation, 0, 1))\n",
    "\n",
    "# # sample\n",
    "# sequence_length = 40\n",
    "# video_len = len(video_lrgb)\n",
    "# sample_interval = np.random.randint(1, video_len // sequence_length + 1)\n",
    "# start_i = np.random.randint(0, video_len - sample_interval * sequence_length + 1)\n",
    "\n",
    "# adv_video = []\n",
    "# for i in range(start_i, start_i + sequence_length*sample_interval, sample_interval):\n",
    "#     if i % 2 == 0:\n",
    "#         adv_video.append(adv_plus[i])\n",
    "#     else:\n",
    "#         adv_video.append(adv_minus[i])\n",
    "# adv_video = torch.stack(adv_video)\n",
    "\n",
    "# adv_video = lrgb2rgb(adv_video)\n",
    "# if aug is not None:\n",
    "#     adv_aug = aug(adv_video)\n",
    "# else:\n",
    "#     adv_aug = adv_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac2c0228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0103, 0.0103, 0.0098, 0.0096, 0.0096, 0.0096, 0.0099, 0.0099, 0.0101,\n",
      "         0.0097, 0.0095, 0.0100, 0.0103, 0.0101, 0.0096, 0.0097, 0.0098, 0.0102,\n",
      "         0.0099, 0.0098, 0.0101, 0.0096, 0.0099, 0.0098, 0.0096, 0.0096, 0.0100,\n",
      "         0.0095, 0.0102, 0.0100, 0.0101, 0.0099, 0.0105, 0.0098, 0.0095, 0.0100,\n",
      "         0.0100, 0.0097, 0.0098, 0.0104, 0.0097, 0.0100, 0.0101, 0.0097, 0.0100,\n",
      "         0.0098, 0.0102, 0.0098, 0.0100, 0.0096, 0.0100, 0.0099, 0.0099, 0.0101,\n",
      "         0.0100, 0.0097, 0.0103, 0.0100, 0.0098, 0.0094, 0.0103, 0.0097, 0.0094,\n",
      "         0.0096, 0.0099, 0.0097, 0.0103, 0.0098, 0.0096, 0.0099, 0.0101, 0.0095,\n",
      "         0.0103, 0.0099, 0.0099, 0.0101, 0.0098, 0.0094, 0.0102, 0.0098, 0.0103,\n",
      "         0.0100, 0.0099, 0.0104, 0.0099, 0.0098, 0.0095, 0.0096, 0.0100, 0.0098,\n",
      "         0.0104, 0.0101, 0.0095, 0.0098, 0.0102, 0.0097, 0.0101, 0.0099, 0.0096,\n",
      "         0.0104, 0.0099]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "outputs = net(adv_aug.unsqueeze(0))\n",
    "print (outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f94ddfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "loss_ce = loss_fn(outputs, labels+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9dd9852b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cudnn RNN backward can only be called in training mode",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31792/2817963574.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss_ce\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/colorfusion/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/colorfusion/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cudnn RNN backward can only be called in training mode"
     ]
    }
   ],
   "source": [
    "loss_ce.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35c89afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_perturbation.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03113be8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91ec981",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if coeff_xy >= 0:\n",
    "    video_xyY = rgb2xyY(images)\n",
    "    plus_xyY = rgb2xyY(adv_plus)\n",
    "    minus_xyY = rgb2xyY(adv_minus)\n",
    "    merged_xyY = (plus_xyY + minus_xyY) / 2\n",
    "    loss_xy = mseloss(merged_xyY, rgb2xyY(video_xyY))\n",
    "\n",
    "loss = loss_ce + coeff_xy * loss_xy\n",
    "loss.backward()\n",
    "\n",
    "grad = self._get_perturb(adv_perturbation.grad.detach())\n",
    "if targeted >= 0:\n",
    "    adv_perturbation.data = adv_perturbation.data - self.eps_iter * grad\n",
    "else:\n",
    "    adv_perturbation.data = adv_perturbation.data + self.eps_iter * grad\n",
    "adv_perturbation.data = self._projection(adv_perturbation.data, 1)\n",
    "adv_perturbation.grad.data.zero_()\n",
    "\n",
    "print (\"iter %d: l_ce, l_xy %.5f, loss %.5f\" % \\\n",
    "       (i, loss_ce.item(), coeff_xy*loss_xy.item(), loss.item()), end='\\r')\n",
    "loss_sum += loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fffdae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c02ccd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "487c91b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRGBLum0Attack():\n",
    "    \"\"\"\n",
    "    LRGB attack in Luminance 0 plane\n",
    "    \"\"\"        \n",
    "    def perturb(self, net, images, labels, config, device, targeted=False, verbose=False, aug=None):\n",
    "        net.eval()\n",
    "        net.lstm.train()\n",
    "        net.attention_layer.train()\n",
    "        batch_size = 1\n",
    "        \n",
    "        # adv_perturbation: lrgb [224, 224, 2]  \n",
    "        input_size = 224\n",
    "        adv_perturbation = torch.zeros((input_size,input_size,2)).to(device)\n",
    "        adv_perturbation.requires_grad = True\n",
    "        expand_to_lrgb = torch.Tensor([[1, 0],[-0.2126/0.7152, -0.0722/0.7152],[0,1]]).T.to(device)\n",
    "\n",
    "        mask_range = input_size\n",
    "        mask_size = int(mask_range * config['row_mask_rate'])\n",
    "        t = torch.arange(0, mask_range, device=device).repeat(batch_size,1)\n",
    "        pad = config['row_mask_pad']\n",
    "        \n",
    "        loss_sum = 0\n",
    "        save_iter = config['save_iter']\n",
    "        coeff_xy = config['coeff_xy']\n",
    "        nb_proj = config['nb_proj']\n",
    "        if coeff_xy >= 0:\n",
    "            mseloss = torch.nn.MSELoss()\n",
    "        for i in range(self.nb_iter):\n",
    "            video_lrgb = rgb2lrgb(images[0])\n",
    "            net.zero_grad()\n",
    "            \n",
    "#           # expand perturbation\n",
    "            l_perturbation = torch.matmul(adv_perturbation,expand_to_lrgb).permute(2,0,1)\n",
    "                \n",
    "            # Random intensity\n",
    "            weight = torch.rand(1).to(device)\n",
    "            l_perturbation = (weight*config['rand_weight']+config['rand_base'])*l_perturbation\n",
    "            \n",
    "            # Row masking\n",
    "            start_row = torch.randint(low=pad, high=mask_range-mask_size-pad, \\\n",
    "                                      size=(batch_size,1), device=device)\n",
    "            mask = t.ge(start_row) & t.lt(start_row+mask_size)\n",
    "            l_perturbation[mask.reshape(1,input_size,1).repeat(3,1,input_size)] = 0\n",
    "\n",
    "            # add perturbation\n",
    "            p_proj = project_perturbation(video_lrgb, l_perturbation, nb_proj)\n",
    "\n",
    "            temp = video_lrgb + p_proj\n",
    "            p_plus = torch.clamp(temp, 0, 1)\n",
    "            idx_plus = p_plus != temp\n",
    "            p_plus = p_plus - video_lrgb\n",
    "\n",
    "            temp = video_lrgb - p_proj\n",
    "            p_minus = torch.clamp(temp, 0, 1)\n",
    "            idx_minus = p_minus != temp\n",
    "            p_minus = video_lrgb - p_minus\n",
    "\n",
    "            p_clipped = torch.where(p_plus.abs() > p_minus.abs(), p_minus, p_plus)\n",
    "            p_clipped = torch.where(idx_plus | idx_minus, p_clipped, p_proj)\n",
    "            l_perturbation = p_clipped\n",
    "            \n",
    "            # plus, minus, mixed\n",
    "            adv_minus = lrgb2rgb(torch.clamp(video_lrgb - l_perturbation, 0, 1))\n",
    "            adv_plus = lrgb2rgb(torch.clamp(video_lrgb + l_perturbation, 0, 1))\n",
    "\n",
    "            # sample\n",
    "            sequence_length = 40\n",
    "            video_len = len(video_lrgb)\n",
    "            sample_interval = np.random.randint(1, video_len // sequence_length + 1)\n",
    "            start_i = np.random.randint(0, video_len - sample_interval * sequence_length + 1)\n",
    "\n",
    "            adv_video = []\n",
    "            for i in range(start_i, start_i + sequence_length*sample_interval, sample_interval):\n",
    "                if i % 2 == 0:\n",
    "                    adv_video.append(adv_plus[i])\n",
    "                else:\n",
    "                    adv_video.append(adv_minus[i])\n",
    "            adv_video = torch.stack(adv_video)\n",
    "            \n",
    "            adv_video = lrgb2rgb(adv_video)\n",
    "            if aug is not None:\n",
    "                adv_aug = aug(adv_video)\n",
    "            else:\n",
    "                adv_aug = adv_video\n",
    "                \n",
    "            print (adv_aug.unsqueeze(0).shape)\n",
    "            outputs = net(adv_aug.unsqueeze(0))\n",
    "            \n",
    "            loss_ce = self.loss_fn(outputs, labels)\n",
    "            \n",
    "            if coeff_xy >= 0:\n",
    "                video_xyY = rgb2xyY(images)\n",
    "                plus_xyY = rgb2xyY(adv_plus)\n",
    "                minus_xyY = rgb2xyY(adv_minus)\n",
    "                merged_xyY = (plus_xyY + minus_xyY) / 2\n",
    "                loss_xy = mseloss(merged_xyY, rgb2xyY(video_xyY))\n",
    "                \n",
    "            loss = loss_ce + coeff_xy * loss_xy\n",
    "            loss.backward()\n",
    "\n",
    "            grad = self._get_perturb(adv_perturbation.grad.detach())\n",
    "            if targeted >= 0:\n",
    "                adv_perturbation.data = adv_perturbation.data - self.eps_iter * grad\n",
    "            else:\n",
    "                adv_perturbation.data = adv_perturbation.data + self.eps_iter * grad\n",
    "            adv_perturbation.data = self._projection(adv_perturbation.data, 1)\n",
    "            adv_perturbation.grad.data.zero_()\n",
    "            \n",
    "            print (\"iter %d: l_ce, l_xy %.5f, loss %.5f\" % \\\n",
    "                   (i, loss_ce.item(), coeff_xy*loss_xy.item(), loss.item()), end='\\r')\n",
    "            loss_sum += loss.item()\n",
    "                \n",
    "#             if (i+1) % save_iter == 0:\n",
    "#                 file_name = '%s_%d.npy' % (config['file_name'], (i+1))\n",
    "#                 np.save(config['file_dir'] + file_name, torch.matmul(adv_perturbation,expand_to_lrgb).permute(0,3,1,2).detach().cpu())\n",
    "#                 print (datetime.datetime.now(), \\\n",
    "#                        'save the perturbation at %dth iterations' % (i+1))\n",
    "                \n",
    "#         file_name = '%s_%d.npy' % (config['file_name'], (i+1))\n",
    "#         np.save(config['file_dir'] + file_name, torch.matmul(adv_perturbation,expand_to_lrgb).permute(0,3,1,2).detach().cpu())\n",
    "#         print (datetime.datetime.now(), \\\n",
    "#                'save the perturbation at %dth iterations' % (i+1))\n",
    "        return torch.matmul(adv_perturbation,expand_to_lrgb).permute(0,3,1,2).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d915d300",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Attack base class\n",
    "class LinfAttack():\n",
    "        \n",
    "    def _rand_init(self, image):\n",
    "        #     np.random.uniform(low=-self.eps, high=self.eps, size=image.shape)\n",
    "        return image + torch.zeros_like(image).uniform_(-self.eps, self.eps)\n",
    "    \n",
    "    def _get_perturb(self, grad):\n",
    "        return torch.sign(grad)\n",
    "    \n",
    "    def _projection(self, perturbation, budget):\n",
    "        return torch.clamp(perturbation, -budget, budget)\n",
    "    \n",
    "class LinfLRGBLum0Attack(LRGBLum0Attack, LinfAttack):\n",
    "    def __init__(self, loss_fn, eps, nb_iter, eps_iter, \n",
    "                 rand_init, clip_min, clip_max):\n",
    "        self.loss_fn = loss_fn\n",
    "        self.eps = eps\n",
    "        self.nb_iter = nb_iter\n",
    "        self.eps_iter = eps_iter\n",
    "        self.rand_init = rand_init\n",
    "        self.clip_min = clip_min\n",
    "        self.clip_max = clip_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "322294fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack = LinfLRGBLum0Attack(torch.nn.CrossEntropyLoss(), eps=0.1, nb_iter=5, eps_iter=0.1, rand_init=False, clip_min=0, clip_max=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "04e51ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 40, 3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sangwooji/miniconda3/envs/colorfusion/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([1, 164, 3, 224, 224])) that is different to the input size (torch.Size([164, 3, 224, 224])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time, but the saved intermediate results have already been freed. Specify retain_graph=True when calling .backward() or autograd.grad() the first time.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11264/2906882055.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'coeff_xy'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nb_proj'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mattack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperturb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_11264/2475097651.py\u001b[0m in \u001b[0;36mperturb\u001b[0;34m(self, net, images, labels, config, device, targeted, verbose, aug)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_ce\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcoeff_xy\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mloss_xy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_perturb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madv_perturbation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/colorfusion/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/colorfusion/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time, but the saved intermediate results have already been freed. Specify retain_graph=True when calling .backward() or autograd.grad() the first time."
     ]
    }
   ],
   "source": [
    "config = {}\n",
    "config['row_mask_rate'] = 0\n",
    "config['row_mask_pad'] = 0\n",
    "config['rand_weight'] = 0\n",
    "config['rand_base'] = 0\n",
    "config['save_iter'] = 0\n",
    "config['coeff_xy'] = 0 \n",
    "config['nb_proj'] = 1\n",
    "attack.perturb(model, images, labels.to(device), config=config, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d6ec25f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvLSTM(\n",
       "  (encoder): Encoder(\n",
       "    (feature_extractor): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (6): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (7): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (6): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (7): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (8): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (9): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (10): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (11): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (12): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (13): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (14): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (15): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (16): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (17): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (18): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (19): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (20): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (21): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (22): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (23): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (24): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (25): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (26): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (27): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (28): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (29): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (30): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (31): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (32): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (33): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (34): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (35): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (7): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    )\n",
       "    (final): Sequential(\n",
       "      (0): Linear(in_features=2048, out_features=512, bias=True)\n",
       "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (lstm): LSTM(\n",
       "    (lstm): LSTM(512, 1024, batch_first=True, bidirectional=True)\n",
       "  )\n",
       "  (output_layers): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=1024, out_features=101, bias=True)\n",
       "    (4): Softmax(dim=-1)\n",
       "  )\n",
       "  (attention_layer): Linear(in_features=2048, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9db33fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.lstm.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036b78f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cca41e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9e49a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8a0781",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0446ee1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52b3bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old version\n",
    "class LRGBLum0Attack():\n",
    "    \"\"\"\n",
    "    LRGB attack in Luminance 0 plane\n",
    "    \"\"\"        \n",
    "    def perturb(self, net, images, labels, config, device, targeted=False, verbose=False, aug=None):\n",
    "        net.eval()\n",
    "        batch_size = 1\n",
    "        \n",
    "        # adv_perturbation: lrgb [224, 224, 2]  \n",
    "        input_size = 224\n",
    "        adv_perturbation = torch.zeros((input_size,input_size,2)).to(device)\n",
    "        adv_perturbation.requires_grad = True\n",
    "        expand_to_lrgb = torch.Tensor([[1, 0],[-0.2126/0.7152, -0.0722/0.7152],[0,1]]).T.to(device)\n",
    "\n",
    "        mask_range = input_size\n",
    "        mask_size = int(mask_range * config['row_mask_rate'])\n",
    "        t = torch.arange(0, mask_range, device=device).repeat(batch_size,1)\n",
    "        pad = config['row_mask_pad']\n",
    "        \n",
    "        loss_sum = 0\n",
    "        save_iter = config['save_iter']\n",
    "        coeff_xy = config['coeff_xy']\n",
    "        nb_proj = config['nb_proj']\n",
    "        if coeff_xy >= 0:\n",
    "            mseloss = torch.nn.MSELoss()\n",
    "        for i in range(self.nb_iter):\n",
    "            video = images.clone()[0]\n",
    "            video_lrgb = rgb2lrgb(video)\n",
    "            net.zero_grad()\n",
    "            \n",
    "#           # expand perturbation\n",
    "            l_perturbation = torch.matmul(adv_perturbation,expand_to_lrgb).permute(2,0,1)\n",
    "                \n",
    "            # Random intensity\n",
    "            weight = torch.rand(1).to(device)\n",
    "            l_perturbation = (weight*config['rand_weight']+config['rand_base'])*l_perturbation\n",
    "            \n",
    "            # Row masking\n",
    "            start_row = torch.randint(low=pad, high=mask_range-mask_size-pad, \\\n",
    "                                      size=(batch_size,1), device=device)\n",
    "            mask = t.ge(start_row) & t.lt(start_row+mask_size)\n",
    "            l_perturbation[mask.reshape(1,input_size,1).repeat(3,1,input_size)] = 0\n",
    "\n",
    "            # add perturbation\n",
    "            p_proj = project_perturbation(video_lrgb, l_perturbation, nb_proj)\n",
    "            for i, image in enumerate(video_lrgb):\n",
    "                if i % 2 == 0:\n",
    "                    image = image + p_proj[i]\n",
    "                else:\n",
    "                    image = image - p_proj[i]\n",
    "            clipped = torch.clamp(video_lrgb, 0, 1)\n",
    "\n",
    "            # sample\n",
    "            sequence_length = 40\n",
    "            video_len = len(clipped)\n",
    "            sample_interval = np.random.randint(1, video_len // sequence_length + 1)\n",
    "            start_i = np.random.randint(0, video_len - sample_interval * sequence_length + 1)\n",
    "\n",
    "            adv_video = []\n",
    "            for i in range(start_i, start_i + sequence_length*sample_interval, sample_interval):\n",
    "                adv_video.append(clipped[i])\n",
    "            adv_video = torch.stack(adv_video)\n",
    "            \n",
    "            adv_video = lrgb2rgb(adv_video)\n",
    "            if aug is not None:\n",
    "                adv_aug = aug(adv_video)\n",
    "            else:\n",
    "                adv_aug = adv_video\n",
    "            outputs = net(adv_aug)\n",
    "            \n",
    "            loss_ce = self.loss_fn(outputs, labels)\n",
    "            \n",
    "            if coeff_xy >= 0:\n",
    "                video_compen = images.clone()[0]\n",
    "                for i, image in enumerate(video_compen):\n",
    "                    if i % 2 == 0:\n",
    "                        image = image - p_proj[i]\n",
    "                    else:\n",
    "                        image = image + p_proj[i]\n",
    "                video_compen = torch.clamp(video_compen, 0, 1)\n",
    "                \n",
    "                plus_xyY = rgb2xyY(adv_video)\n",
    "                minus_xyY = lrgb2xyY(video_compen)\n",
    "                merged_xyY = (plus_xyY + minus_xyY) / 2\n",
    "                loss_xy = mseloss(merged_xyY, rgb2xyY(video))\n",
    "                \n",
    "            loss = loss_ce + coeff_xy * loss_xy\n",
    "            loss.backward()\n",
    "\n",
    "            grad = self._get_perturb(adv_perturbation.grad.detach())\n",
    "            if targeted >= 0:\n",
    "                adv_perturbation.data = adv_perturbation.data - self.eps_iter * grad\n",
    "            else:\n",
    "                adv_perturbation.data = adv_perturbation.data + self.eps_iter * grad\n",
    "            adv_perturbation.data = self._projection(adv_perturbation.data, 1)\n",
    "            adv_perturbation.grad.data.zero_()\n",
    "            \n",
    "            print (\"iter %d: l_ce, l_xy %.5f, loss %.5f\" % \\\n",
    "                   (i, loss_ce.item(), coeff_xy*loss_xy.item(), loss.item()), end='\\r')\n",
    "            loss_sum += loss.item()\n",
    "                \n",
    "#             if (i+1) % save_iter == 0:\n",
    "#                 file_name = '%s_%d.npy' % (config['file_name'], (i+1))\n",
    "#                 np.save(config['file_dir'] + file_name, torch.matmul(adv_perturbation,expand_to_lrgb).permute(0,3,1,2).detach().cpu())\n",
    "#                 print (datetime.datetime.now(), \\\n",
    "#                        'save the perturbation at %dth iterations' % (i+1))\n",
    "                \n",
    "#         file_name = '%s_%d.npy' % (config['file_name'], (i+1))\n",
    "#         np.save(config['file_dir'] + file_name, torch.matmul(adv_perturbation,expand_to_lrgb).permute(0,3,1,2).detach().cpu())\n",
    "#         print (datetime.datetime.now(), \\\n",
    "#                'save the perturbation at %dth iterations' % (i+1))\n",
    "        return torch.matmul(adv_perturbation,expand_to_lrgb).permute(0,3,1,2).detach()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
